# ADL-semg-accelerometer-force-data
Collection of Multi-modal data including sEMG, accelerometer and force exerted on each data collected from 3 subjects for a set of 6 activities of daily living

We contribute a dataset containing EMG, accelerometer and force sensor data for a set of 6 ADLs. These include ``folding laundry'', ``writing with pen'', ``opening a jar'', ``screwing lightbult'', ``combing hair'', and ``tying shoelaces'', selected to cover a variety of hand motions and positions. The setup includes FlexiForce A201 111N Force Sensors, integrated into the wearable sEMG biosensing system (https://www.nature.com/articles/s41928-020-00510-8). The adapter PCB was re-designed to interface 5 force sensors and the flexible 64-channel sEMG electrode array with the WAND device (https://www.nature.com/articles/s41551-018-0323-x) - an 8-layer PCB that accommodates an accelerometer, the custom-designed sensing and digitizing ASIC (https://ieeexplore.ieee.org/abstract/document/8008543), and components for processing/telemetry. In operating WAND, the wide input voltage mode with a range of 400 mV was used and data was collected at 1 kS/s. The FlexiForce A201 111N Sensors had a max sensor length of 190.5 mm that attached to the tips of each subject’s fingers in order to collect data on force exertion.
 
We collected data on 3 subjects, using a graphical user interface (GUI) to guide subjects through 6 ADLs. The 6 ADLs covered a variety of arm and hand motions: folding laundry, writing with a pen, opening a jar, screwing a lightbulb, combing hair, and tying a shoelace. For each ADL, the subject first watched a tutorial explaining how to perform the ADL. Then the subject ran through 5 repetitions of the ADL in a controlled time frame during which they were guided through various sub-tasks. Subsequently, they ran through 5 repetitions of the ADL in a variable time frame in which they performed the ADL at their own discretion, unguided.

During the controlled time frame, each of the 6 ADLs were broken down into their sub-tasks, with each sub-task lasting a duration of 5 seconds. Folding laundry consisted of 8 subtasks in which the subject was asked to lift a jacket off the table, move it to the right, and fold it on top of the table. Writing with a pen consisted of 15 subtasks in which the subject was asked to use a two-finger pinch to lift a pen above the table and to write “hello” on a piece of paper located on the table. Opening a jar consisted of 14 subtasks in which the subject was asked to power grip the jar with their non-equipped hand (from which no data was being collected) in order to use their equipped hand to untwist the cap 90 degrees a total of 4 times, at which point they were instructed to remove the cap. Screwing a lightbulb consisted of 13 subtasks in which the subject was asked to grasp a lightbulb and then to screw it into a lamp, twisting it 180 degrees a total of 4 times. Combing hair consisted of 16 subtasks in which the subject was asked to grip a comb and lift it up and down through their hair a total of 4 times. Tying a shoelace consisted of 9 subtasks in which the subject was asked to follow a particular method of tying a shoelace that involved using a mirrored L grip and closed pinch. 

During the variable time frame, each ADL lasted 20 seconds during which subjects were free to achieve the task at their own pace. 

Overall, we integrated sEMG and accelerometer data for ADL recognition and sub-task detection, respectively. The sub-tasks selected within each ADL correspond to changes in prosthetic actuation (e.g releasing, lifting, changing of grip, etc.). The FlexiForce A201 111N Sensors provided feedback for shared control, completing the user’s intent while managing fine motor control. All experiments were performed in strict compliance with the guidelines of IRB and were approved by the Committee for Protection of Human Subjects at University of California, Berkeley (Protocol title: Continuous EMG for Learning Activities of Daily Living Study, Protocol number: 2021-11-14838).

Most existing sEMG datasets are limited to specific movements or static gestures. Prior sEMG datasets that were collected during ADL tasks do not include feedback information, which a controller could heavily benefit from for object manipulation, or labels for various parts of the ADL, which enables more specific grasp selection and timing. This dataset collects sEMG and accelerometer information during ADLs along with the critical feedback force sensors, includes labels for sub-tasks and also adds the controlled timing scenario in which tasks are done guided under specific timing. The controlled time frame serves as a foundation for analyzing data collected in the variable, unguided time frame which is also included. The two levels of timing complexity aid in control scheme exploration and development.

We have included the features extracted with a mean absolute value over 50ms non-overlapping windows for each subject. The data is labelled by experiment which corresponds to the ADLs above and stored in .mat files that contain variables for accelerometer, emg and force for both controlled time experiments (labeled by \_disc) and variable time labeled by (\_cont). The subgesturelabel variable corresponds to sub-task labels which only exists for the controlled time experiments while the trial label shows which repetition of the ADL it is. For the variable time, the subtrial label shows the ADL label for variable time experiments while the trial albel shows which repetition of the ADL it is. -1 corresponds to invalid data. The code written to extract sEMG and accelerometer data and basic HDC blocks is based on prior work by Andy Zhou (https://arxiv.org/abs/2103.05267).

The scripts to classify the activity using HDC are included as well. The HDC blocks are included in the HDC folder and the jupyter notebook used to classify and process the feature data is in the analysis folder and is named sub_gesture_classification_sweeping.ipynb. To run the analysis change the feature directory to correspond to the different subjects and modify the line below it to specify the subject as well. 

For the raw data, please contact the authors at allymenon@berkeley.edu. There are 5 files for subject 1, containing the full ADL collections including 5 controlled time and 5 variable time repetitions for each. The features can be extracted using daily_activity_feature_extraction.ipynb. For subject 2 and 3, each file corresponds to one repetition of the ADL. The first 5 are the controlled time and the second 5 are the variable time. The features can be extracted using the single_trial_daily_activity_feature_extraction.ipynb. 


